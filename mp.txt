from google.colab import drive
drive.mount('/content/drive/')
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Convolution2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(rescale = 1./255,shear_range = 0.2, zoom_range = 0.2,
                                   horizontal_flip = True,)
test_datagen = ImageDataGenerator(rescale = 1./255)
train_set = train_datagen.flow_from_directory(r"/content/drive/MyDrive/Drive Folder.zip (Unzipped Files)/Drive Folder/Train",target_size = (64,64),
                          batch_size = 32, class_mode = 'categorical')
test_set = test_datagen.flow_from_directory(r"/content/drive/MyDrive/Drive Folder.zip (Unzipped Files)/Drive Folder/Test",target_size = (64,64),
                          batch_size = 32, class_mode = 'categorical')
print(train_set.class_indices)
model = Sequential()
model.add(Convolution2D(32,(3,3),input_shape = (64,64,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Flatten())
model.add(Dense(units=128,activation='relu'))#input layer
model.add(Dense(units=20,activation='softmax'))#output layer
model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])
history = model.fit(train_set, steps_per_epoch=13, epochs=30,validation_data=test_set,
                    validation_steps = 3)
model.save("species.h5")
import matplotlib.pyplot as plt
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()
plt.show()
import numpy as np
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()

for i in uploaded.keys():
 
  # predicting images
  path = i
  img = image.load_img(path, target_size=(64, 64))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  pred = model.predict(images, batch_size=32)
  maxi = max(max(pred))
  p = pred[0]
  print(pred)
  print("Maximum Probability Value:", maxi)
  print("Predicted Species:", i)